{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NodeSysCa/Tensor-1/blob/main/Copy_of_C3W4_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFWbEb6uGbN-"
      },
      "source": [
        "# Week 4: Predicting the next word\n",
        "\n",
        "Welcome to this assignment! During this week you saw how to create a model that will predict the next word in a text sequence, now you will implement such model and train it using a corpus of Shakespeare's sonnets, while also creating some helper functions to pre-process the data.\n",
        "\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp4A-ZBwSN11"
      },
      "source": [
        "_**NOTE:** To prevent errors from the autograder, pleave avoid editing or deleting non-graded cells in this notebook . Please only put your solutions in between the `### START CODE HERE` and `### END CODE HERE` code comments, and also refrain from adding any new cells._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BOwsuGQQY9OL",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTxqlHqKHzhr"
      },
      "source": [
        "For this assignment you will be using the [Shakespeare Sonnets Dataset](https://www.opensourceshakespeare.org/views/sonnets/sonnet_view.php?range=viewrange&sonnetrange1=1&sonnetrange2=154), which contains more than 2000 lines of text extracted from Shakespeare's sonnets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WZ4qOUzujMP6",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3bd641-4698-4d96-89a6-1a3140cac46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "100% 93.6k/93.6k [00:00<00:00, 95.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# sonnets.txt\n",
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Pfd-nYKij5yY",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9cd385-82e9-4729-8b98-2e93ec8f14c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2159 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "from fairest creatures we desire increase,\n",
            "that thereby beauty's rose might never die,\n",
            "but as the riper should by time decease,\n",
            "his tender heir might bear his memory:\n",
            "but thou, contracted to thine own bright eyes,\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define path for file with sonnets\n",
        "SONNETS_FILE = './sonnets.txt'\n",
        "\n",
        "# Read the data\n",
        "with open('./sonnets.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imB15zrSNhA1"
      },
      "source": [
        "## Tokenizing the text\n",
        "\n",
        "Now fit the Tokenizer to the corpus and save the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AAhM_qAZk0o5",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77-0sA46OETa"
      },
      "source": [
        "When converting the text into sequences you can use the `texts_to_sequences` method as you have done throughout this course.\n",
        "\n",
        "In the next graded function you will need to process this corpus one line at a time. Given this, it is important to keep in mind that the way you are feeding the data unto this method affects the result. Check the following example to make this clearer.\n",
        "\n",
        "The first example of the corpus is a string and looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tqhPxdeXlfjh",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "422320c8-fa08-4a20-893d-0ac28005ebe6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from fairest creatures we desire increase,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "corpus[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFMP4z11O3os"
      },
      "source": [
        "If you pass this text directly into the `texts_to_sequences` method you will get an unexpected result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EMSEhmbzNZCE",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af2ac8e-8215-4601-e715-6870b34c8c98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [58],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer.texts_to_sequences(corpus[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPZmZtpEPEeI"
      },
      "source": [
        "This happened because `texts_to_sequences` expects a list and you are providing a string. However a string is still and `iterable` in Python so you will get the word index of every character in the string.\n",
        "\n",
        "Instead you need to place the example whithin a list before passing it to the method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Qmgo-vXhk4nd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e54b6a7-3e39-4cd1-bde2-740b5ac7a294"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer.texts_to_sequences([corpus[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DU7wK-eQ5dc"
      },
      "source": [
        "Notice that you received the sequence wrapped inside a list so in order to get only the desired sequence you need to explicitly get the first item in the list like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kpTy8WmIQ57P",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf59efa-bb78-4136-97c6-6f21f18614dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 417, 877, 166, 213, 517]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqy9KjXRJ9A"
      },
      "source": [
        "## Generating n_grams\n",
        "\n",
        "Now complete the `n_gram_seqs` function below. This function receives the fitted tokenizer and the corpus (which is a list of strings) and should return a list containing the `n_gram` sequences for each line in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "iy4baJMDl6kj",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: n_gram_seqs\n",
        "def n_gram_seqs(corpus, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "\n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "\n",
        "    Returns:\n",
        "        input_sequences (list of int): the n-gram sequences for each line in the corpus\n",
        "    \"\"\"\n",
        "    input_sequences = []\n",
        "\n",
        "    ### START CODE HERE\n",
        "    for line in corpus:\n",
        "\t    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\t  # Loop over the line several times to generate the subphrases\n",
        "\t    for i in range(1, len(token_list)):\n",
        "\t  \t  n_gram_sequence = token_list[:i+1]\n",
        "\t\t# Append the subphrase to the sequences list\n",
        "\t  \t  input_sequences.append(n_gram_sequence)\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DlKqW2pfM7G3",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b15fdf-4496-4aa7-9f5c-ee987c792a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with one example\n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HL8Ug6UU0Jt"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_gram sequences for first example look like this:\n",
        "\n",
        "[[34, 417],\n",
        " [34, 417, 877],\n",
        " [34, 417, 877, 166],\n",
        " [34, 417, 877, 166, 213],\n",
        " [34, 417, 877, 166, 213, 517]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wtPpCcBjNc4c",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645407e0-3925-471a-bde4-ffa62de3af2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156],\n",
              " [8, 878, 134, 351, 102, 156, 199],\n",
              " [16, 22],\n",
              " [16, 22, 2],\n",
              " [16, 22, 2, 879],\n",
              " [16, 22, 2, 879, 61],\n",
              " [16, 22, 2, 879, 61, 30],\n",
              " [16, 22, 2, 879, 61, 30, 48],\n",
              " [16, 22, 2, 879, 61, 30, 48, 634],\n",
              " [25, 311],\n",
              " [25, 311, 635],\n",
              " [25, 311, 635, 102],\n",
              " [25, 311, 635, 102, 200],\n",
              " [25, 311, 635, 102, 200, 25],\n",
              " [25, 311, 635, 102, 200, 25, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with a bigger corpus\n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIzecMczU9UB"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_gram sequences for next 3 examples look like this:\n",
        "\n",
        "[[8, 878],\n",
        " [8, 878, 134],\n",
        " [8, 878, 134, 351],\n",
        " [8, 878, 134, 351, 102],\n",
        " [8, 878, 134, 351, 102, 156],\n",
        " [8, 878, 134, 351, 102, 156, 199],\n",
        " [16, 22],\n",
        " [16, 22, 2],\n",
        " [16, 22, 2, 879],\n",
        " [16, 22, 2, 879, 61],\n",
        " [16, 22, 2, 879, 61, 30],\n",
        " [16, 22, 2, 879, 61, 30, 48],\n",
        " [16, 22, 2, 879, 61, 30, 48, 634],\n",
        " [25, 311],\n",
        " [25, 311, 635],\n",
        " [25, 311, 635, 102],\n",
        " [25, 311, 635, 102, 200],\n",
        " [25, 311, 635, 102, 200, 25],\n",
        " [25, 311, 635, 102, 200, 25, 278]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V_RjFWQSu"
      },
      "source": [
        "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "laMwiRUpmuSd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f57414-baad-4f13-b265-9d02c4aa6ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences have length: 15462\n",
            "maximum length of sequences is: 11\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OciMdmEdE9L"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_grams of input_sequences have length: 15462\n",
        "maximum length of sequences is: 11\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHY7HroqWq12"
      },
      "source": [
        "## Add padding to the sequences\n",
        "\n",
        "Now code the `pad_seqs` function which will pad any given sequences to the desired maximum length. Notice that this function receives a list of sequences and should return a numpy array with the padded sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "deletable": false,
        "id": "WW1-qAZaWOhC",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: pad_seqs\n",
        "def pad_seqs(input_sequences, maxlen):\n",
        "    \"\"\"\n",
        "    Pads tokenized sequences to the same length\n",
        "\n",
        "    Args:\n",
        "        input_sequences (list of int): tokenized sequences to pad\n",
        "        maxlen (int): maximum length of the token sequences\n",
        "\n",
        "    Returns:\n",
        "        padded_sequences (array of int): tokenized sequences padded to the same length\n",
        "    \"\"\"\n",
        "    ### START CODE HERE\n",
        "    padded_sequences = None\n",
        "    input_sequences = pad_sequences(input_sequences, maxlen=maxlen, padding='pre')\n",
        "    #xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    #ys = to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "    return input_sequences\n",
        "    ### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IqVQ0pb3YHLr",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222a4c25-60c4-45c6-be5e-bb713238582e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0  34 417]\n",
            " [  0   0   0  34 417 877]\n",
            " [  0   0  34 417 877 166]\n",
            " [  0  34 417 877 166 213]\n",
            " [ 34 417 877 166 213 517]]\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, max([len(x) for x in first_example_sequence]))\n",
        "print(first_padded_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_avDznXRnU"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "array([[  0,   0,   0,   0,  34, 417],\n",
        "       [  0,   0,   0,  34, 417, 877],\n",
        "       [  0,   0,  34, 417, 877, 166],\n",
        "       [  0,  34, 417, 877, 166, 213],\n",
        "       [ 34, 417, 877, 166, 213, 517]], dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "j56_UCOBYzZt",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec452e7-81aa-436e-b0ba-eb69ff072e31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
              "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
              "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
              "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
              "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
              "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
              "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
              "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
              "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
              "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
              "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
              "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
              "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
              "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
              "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
              "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
              "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
              "       [  0,  25, 311, 635, 102, 200,  25, 278]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rmcDluOXcIU"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
        "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
        "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
        "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
        "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
        "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
        "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
        "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
        "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
        "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
        "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
        "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
        "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
        "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
        "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
        "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
        "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
        "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
        "       [  0,  25, 311, 635, 102, 200,  25, 278]], dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rgK-Q_micEYA",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42877c82-5466-448c-d8ae-e22664d6dc88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (15462, 11)\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59RD1YYNc7CW"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "padded corpus has shape: (15462, 11)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOidyPrXxf7"
      },
      "source": [
        "## Split the data into features and labels\n",
        "\n",
        "Before feeding the data into the neural network you should split it into features and labels. In this case the features will be the padded n_gram sequences with the last word removed from them and the labels will be the removed word.\n",
        "\n",
        "Complete the `features_and_labels` function below. This function expects the padded n_gram sequences as input and should return a tuple containing the features and the one hot encoded labels.\n",
        "\n",
        "Notice that the function also receives the total of words in the corpus, this parameter will be very important when one hot enconding the labels since every word in the corpus will be a label at least once. If you need a refresh of how the `to_categorical` function works take a look at the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "deletable": false,
        "id": "9WGGbYdnZdmJ",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: features_and_labels\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    \"\"\"\n",
        "    Generates features and labels from n-grams\n",
        "\n",
        "    Args:\n",
        "        input_sequences (list of int): sequences to split features and labels from\n",
        "        total_words (int): vocabulary size\n",
        "\n",
        "    Returns:\n",
        "        features, one_hot_labels (array of int, array of int): arrays of features and one-hot encoded labels\n",
        "    \"\"\"\n",
        "    ### START CODE HERE\n",
        "    features = None\n",
        "    labels = None\n",
        "    one_hot_labels = None\n",
        "    # Create inputs and label by splitting the last token in the subphrases\n",
        "    features, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    # Convert the label into one-hot arrays\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return features, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "23DolaBRaIAZ",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b5a37b-8a11-4688-d80b-9dc27e21b718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (5, 3211)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,  34],\n",
              "       [  0,   0,   0,  34, 417],\n",
              "       [  0,   0,  34, 417, 877],\n",
              "       [  0,  34, 417, 877, 166],\n",
              "       [ 34, 417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function with the padded n_grams_seq of the first example\n",
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t4yAx2UaQ43"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "labels have shape: (5, 3211)\n",
        "\n",
        "features look like this:\n",
        "\n",
        "array([[  0,   0,   0,   0,  34],\n",
        "       [  0,   0,   0,  34, 417],\n",
        "       [  0,   0,  34, 417, 877],\n",
        "       [  0,  34, 417, 877, 166],\n",
        "       [ 34, 417, 877, 166, 213]], dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GRTuLEt3bRKa",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc09f01-3d00-4eac-fda4-3a3f605da3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (15462, 10)\n",
            "labels have shape: (15462, 3211)\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXSMK_HpdLns"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "features have shape: (15462, 10)\n",
        "labels have shape: (15462, 3211)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltxaOCE_aU6J"
      },
      "source": [
        "## Create the model\n",
        "\n",
        "Now you should define a model architecture capable of achieving an accuracy of at least 80%.\n",
        "\n",
        "Some hints to help you in this task:\n",
        "\n",
        "- An appropriate `output_dim` for the first layer (Embedding) is 100, this is already provided for you.\n",
        "- A Bidirectional LSTM is helpful for this particular problem.\n",
        "- The last layer should have the same number of units as the total number of words in the corpus and a softmax activation function.\n",
        "- This problem can be solved with only two layers (excluding the Embedding) so try out small architectures first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "deletable": false,
        "id": "XrE6kpJFfvRY",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: create_model\n",
        "def create_model(total_words, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Creates a text generator model\n",
        "\n",
        "    Args:\n",
        "        total_words (int): size of the vocabulary for the Embedding layer input\n",
        "        max_sequence_len (int): length of the input sequences\n",
        "\n",
        "    Returns:\n",
        "        model (tf.keras Model): the text generator model\n",
        "    \"\"\"\n",
        "    #model = Sequential()\n",
        "    ### START CODE HERE\n",
        "    model=Sequential([Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
        "          Bidirectional(LSTM(150)),\n",
        "          Dense(total_words, activation='softmax')])\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "          optimizer=Adam(learning_rate=0.005),\n",
        "          metrics=['accuracy'])\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IpX_Gu_gISk",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60722748-f74d-4d11-bb40-bea86da6b4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "484/484 [==============================] - 18s 27ms/step - loss: 6.8045 - accuracy: 0.0283\n",
            "Epoch 2/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 6.1884 - accuracy: 0.0524\n",
            "Epoch 3/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 5.5688 - accuracy: 0.0776\n",
            "Epoch 4/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 4.7353 - accuracy: 0.1257\n",
            "Epoch 5/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 3.7087 - accuracy: 0.2393\n",
            "Epoch 6/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.7300 - accuracy: 0.4149\n",
            "Epoch 7/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 2.0088 - accuracy: 0.5588\n",
            "Epoch 8/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.5062 - accuracy: 0.6709\n",
            "Epoch 9/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.1763 - accuracy: 0.7440\n",
            "Epoch 10/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9622 - accuracy: 0.7938\n",
            "Epoch 11/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.8377 - accuracy: 0.8173\n",
            "Epoch 12/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.7569 - accuracy: 0.8330\n",
            "Epoch 13/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.7174 - accuracy: 0.8379\n",
            "Epoch 14/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7113 - accuracy: 0.8383\n",
            "Epoch 15/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.8813 - accuracy: 0.7884\n",
            "Epoch 16/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1367 - accuracy: 0.7132\n",
            "Epoch 17/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.8345 - accuracy: 0.7925\n",
            "Epoch 18/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.6814 - accuracy: 0.8362\n",
            "Epoch 19/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6274 - accuracy: 0.8476\n",
            "Epoch 20/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.6113 - accuracy: 0.8475\n",
            "Epoch 21/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6075 - accuracy: 0.8472\n",
            "Epoch 22/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6041 - accuracy: 0.8474\n",
            "Epoch 23/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6042 - accuracy: 0.8463\n",
            "Epoch 24/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6424 - accuracy: 0.8370\n",
            "Epoch 25/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.5762 - accuracy: 0.5964\n",
            "Epoch 26/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 1.1038 - accuracy: 0.7112\n",
            "Epoch 27/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7280 - accuracy: 0.8135\n",
            "Epoch 28/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.6192 - accuracy: 0.8421\n",
            "Epoch 29/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5910 - accuracy: 0.8490\n",
            "Epoch 30/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5811 - accuracy: 0.8489\n",
            "Epoch 31/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5742 - accuracy: 0.8487\n",
            "Epoch 32/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5721 - accuracy: 0.8501\n",
            "Epoch 33/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5743 - accuracy: 0.8495\n",
            "Epoch 34/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5798 - accuracy: 0.8484\n",
            "Epoch 35/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.8605 - accuracy: 0.7745\n",
            "Epoch 36/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.6313 - accuracy: 0.5876\n",
            "Epoch 37/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.9164 - accuracy: 0.7559\n",
            "Epoch 38/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.6787 - accuracy: 0.8230\n",
            "Epoch 39/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6068 - accuracy: 0.8434\n",
            "Epoch 40/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5746 - accuracy: 0.8499\n",
            "Epoch 41/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5655 - accuracy: 0.8497\n",
            "Epoch 42/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5655 - accuracy: 0.8492\n",
            "Epoch 43/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5611 - accuracy: 0.8498\n",
            "Epoch 44/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5590 - accuracy: 0.8498\n",
            "Epoch 45/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5686 - accuracy: 0.8486\n",
            "Epoch 46/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.2306 - accuracy: 0.6867\n",
            "Epoch 47/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 1.4026 - accuracy: 0.6400\n",
            "Epoch 48/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.8608 - accuracy: 0.7665\n",
            "Epoch 49/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6635 - accuracy: 0.8247\n",
            "Epoch 50/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5900 - accuracy: 0.8459\n",
            "Epoch 51/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5664 - accuracy: 0.8496\n",
            "Epoch 52/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5593 - accuracy: 0.8502\n",
            "Epoch 53/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5554 - accuracy: 0.8482\n",
            "Epoch 54/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5515 - accuracy: 0.8492\n",
            "Epoch 55/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5531 - accuracy: 0.8488\n",
            "Epoch 56/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5624 - accuracy: 0.8476\n",
            "Epoch 57/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.1053 - accuracy: 0.7176\n",
            "Epoch 58/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.4119 - accuracy: 0.6318\n",
            "Epoch 59/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.8754 - accuracy: 0.7632\n",
            "Epoch 60/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6698 - accuracy: 0.8229\n",
            "Epoch 61/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.6001 - accuracy: 0.8412\n",
            "Epoch 62/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5778 - accuracy: 0.8470\n",
            "Epoch 63/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5587 - accuracy: 0.8500\n",
            "Epoch 64/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5544 - accuracy: 0.8489\n",
            "Epoch 65/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5533 - accuracy: 0.8496\n",
            "Epoch 66/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5473 - accuracy: 0.8504\n",
            "Epoch 67/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5463 - accuracy: 0.8485\n",
            "Epoch 68/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5486 - accuracy: 0.8485\n",
            "Epoch 69/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9199 - accuracy: 0.7601\n",
            "Epoch 70/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.6179 - accuracy: 0.5966\n",
            "Epoch 71/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9766 - accuracy: 0.7366\n",
            "Epoch 72/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6970 - accuracy: 0.8113\n",
            "Epoch 73/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6006 - accuracy: 0.8399\n",
            "Epoch 74/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5676 - accuracy: 0.8476\n",
            "Epoch 75/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5552 - accuracy: 0.8496\n",
            "Epoch 76/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5487 - accuracy: 0.8497\n",
            "Epoch 77/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5458 - accuracy: 0.8490\n",
            "Epoch 78/200\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 0.5469 - accuracy: 0.8494\n",
            "Epoch 79/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5432 - accuracy: 0.8509\n",
            "Epoch 80/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5472 - accuracy: 0.8486\n",
            "Epoch 81/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.0448 - accuracy: 0.7315\n",
            "Epoch 82/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.5674 - accuracy: 0.6137\n",
            "Epoch 83/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9602 - accuracy: 0.7401\n",
            "Epoch 84/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7059 - accuracy: 0.8099\n",
            "Epoch 85/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6101 - accuracy: 0.8393\n",
            "Epoch 86/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5761 - accuracy: 0.8458\n",
            "Epoch 87/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5586 - accuracy: 0.8492\n",
            "Epoch 88/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5477 - accuracy: 0.8500\n",
            "Epoch 89/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5448 - accuracy: 0.8497\n",
            "Epoch 90/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5429 - accuracy: 0.8499\n",
            "Epoch 91/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5397 - accuracy: 0.8501\n",
            "Epoch 92/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5441 - accuracy: 0.8490\n",
            "Epoch 93/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9153 - accuracy: 0.7582\n",
            "Epoch 94/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.4390 - accuracy: 0.6340\n",
            "Epoch 95/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.9394 - accuracy: 0.7416\n",
            "Epoch 96/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.7133 - accuracy: 0.8053\n",
            "Epoch 97/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6132 - accuracy: 0.8335\n",
            "Epoch 98/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5751 - accuracy: 0.8455\n",
            "Epoch 99/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5591 - accuracy: 0.8476\n",
            "Epoch 100/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5520 - accuracy: 0.8487\n",
            "Epoch 101/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5489 - accuracy: 0.8485\n",
            "Epoch 102/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5530 - accuracy: 0.8470\n",
            "Epoch 103/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6679 - accuracy: 0.8170\n",
            "Epoch 104/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 1.1602 - accuracy: 0.6942\n",
            "Epoch 105/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.9636 - accuracy: 0.7371\n",
            "Epoch 106/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7189 - accuracy: 0.8014\n",
            "Epoch 107/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6240 - accuracy: 0.8296\n",
            "Epoch 108/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5749 - accuracy: 0.8448\n",
            "Epoch 109/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5581 - accuracy: 0.8478\n",
            "Epoch 110/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5430 - accuracy: 0.8492\n",
            "Epoch 111/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5376 - accuracy: 0.8495\n",
            "Epoch 112/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5339 - accuracy: 0.8492\n",
            "Epoch 113/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5301 - accuracy: 0.8500\n",
            "Epoch 114/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5294 - accuracy: 0.8509\n",
            "Epoch 115/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5373 - accuracy: 0.8478\n",
            "Epoch 116/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 1.0430 - accuracy: 0.7315\n",
            "Epoch 117/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.3427 - accuracy: 0.6594\n",
            "Epoch 118/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.8713 - accuracy: 0.7609\n",
            "Epoch 119/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6784 - accuracy: 0.8136\n",
            "Epoch 120/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5988 - accuracy: 0.8396\n",
            "Epoch 121/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5714 - accuracy: 0.8445\n",
            "Epoch 122/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5576 - accuracy: 0.8470\n",
            "Epoch 123/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5643 - accuracy: 0.8454\n",
            "Epoch 124/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5623 - accuracy: 0.8461\n",
            "Epoch 125/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6087 - accuracy: 0.8327\n",
            "Epoch 126/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7951 - accuracy: 0.7770\n",
            "Epoch 127/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.8907 - accuracy: 0.7577\n",
            "Epoch 128/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7943 - accuracy: 0.7782\n",
            "Epoch 129/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6754 - accuracy: 0.8146\n",
            "Epoch 130/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6054 - accuracy: 0.8335\n",
            "Epoch 131/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5834 - accuracy: 0.8388\n",
            "Epoch 132/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5847 - accuracy: 0.8377\n",
            "Epoch 133/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5781 - accuracy: 0.8403\n",
            "Epoch 134/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5938 - accuracy: 0.8368\n",
            "Epoch 135/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6457 - accuracy: 0.8208\n",
            "Epoch 136/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7140 - accuracy: 0.8035\n",
            "Epoch 137/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.7210 - accuracy: 0.8020\n",
            "Epoch 138/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6881 - accuracy: 0.8091\n",
            "Epoch 139/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6246 - accuracy: 0.8263\n",
            "Epoch 140/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5974 - accuracy: 0.8346\n",
            "Epoch 141/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5869 - accuracy: 0.8379\n",
            "Epoch 142/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5860 - accuracy: 0.8377\n",
            "Epoch 143/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5948 - accuracy: 0.8353\n",
            "Epoch 144/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6236 - accuracy: 0.8272\n",
            "Epoch 145/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6995 - accuracy: 0.8050\n",
            "Epoch 146/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.7046 - accuracy: 0.8025\n",
            "Epoch 147/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6626 - accuracy: 0.8165\n",
            "Epoch 148/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6299 - accuracy: 0.8215\n",
            "Epoch 149/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6025 - accuracy: 0.8316\n",
            "Epoch 150/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5793 - accuracy: 0.8394\n",
            "Epoch 151/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5744 - accuracy: 0.8399\n",
            "Epoch 152/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5689 - accuracy: 0.8393\n",
            "Epoch 153/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6049 - accuracy: 0.8326\n",
            "Epoch 154/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6547 - accuracy: 0.8174\n",
            "Epoch 155/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6739 - accuracy: 0.8125\n",
            "Epoch 156/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6513 - accuracy: 0.8187\n",
            "Epoch 157/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6225 - accuracy: 0.8269\n",
            "Epoch 158/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6279 - accuracy: 0.8263\n",
            "Epoch 159/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6158 - accuracy: 0.8274\n",
            "Epoch 160/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6031 - accuracy: 0.8321\n",
            "Epoch 161/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5891 - accuracy: 0.8360\n",
            "Epoch 162/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.5769 - accuracy: 0.8386\n",
            "Epoch 163/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5909 - accuracy: 0.8337\n",
            "Epoch 164/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6108 - accuracy: 0.8305\n",
            "Epoch 165/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6398 - accuracy: 0.8223\n",
            "Epoch 166/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6607 - accuracy: 0.8178\n",
            "Epoch 167/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6556 - accuracy: 0.8159\n",
            "Epoch 168/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6269 - accuracy: 0.8262\n",
            "Epoch 169/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5922 - accuracy: 0.8366\n",
            "Epoch 170/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5873 - accuracy: 0.8356\n",
            "Epoch 171/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5955 - accuracy: 0.8337\n",
            "Epoch 172/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5977 - accuracy: 0.8306\n",
            "Epoch 173/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6050 - accuracy: 0.8317\n",
            "Epoch 174/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6126 - accuracy: 0.8294\n",
            "Epoch 175/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6285 - accuracy: 0.8232\n",
            "Epoch 176/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6169 - accuracy: 0.8285\n",
            "Epoch 177/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6271 - accuracy: 0.8260\n",
            "Epoch 178/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6389 - accuracy: 0.8209\n",
            "Epoch 179/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6267 - accuracy: 0.8243\n",
            "Epoch 180/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6122 - accuracy: 0.8275\n",
            "Epoch 181/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6007 - accuracy: 0.8293\n",
            "Epoch 182/200\n",
            "484/484 [==============================] - 6s 11ms/step - loss: 0.5986 - accuracy: 0.8331\n",
            "Epoch 183/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6043 - accuracy: 0.8332\n",
            "Epoch 184/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.5946 - accuracy: 0.8339\n",
            "Epoch 185/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5950 - accuracy: 0.8314\n",
            "Epoch 186/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6011 - accuracy: 0.8325\n",
            "Epoch 187/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.5954 - accuracy: 0.8343\n",
            "Epoch 188/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6008 - accuracy: 0.8318\n",
            "Epoch 189/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6080 - accuracy: 0.8291\n",
            "Epoch 190/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6150 - accuracy: 0.8279\n",
            "Epoch 191/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6265 - accuracy: 0.8241\n",
            "Epoch 192/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6169 - accuracy: 0.8254\n",
            "Epoch 193/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6013 - accuracy: 0.8301\n",
            "Epoch 194/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6002 - accuracy: 0.8307\n",
            "Epoch 195/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.5973 - accuracy: 0.8309\n",
            "Epoch 196/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.6022 - accuracy: 0.8306\n",
            "Epoch 197/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6052 - accuracy: 0.8296\n",
            "Epoch 198/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.6092 - accuracy: 0.8271\n",
            "Epoch 199/200\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 0.6145 - accuracy: 0.8258\n",
            "Epoch 200/200\n",
            "484/484 [==============================] - 5s 9ms/step - loss: 0.6162 - accuracy: 0.8272\n"
          ]
        }
      ],
      "source": [
        "# Get the untrained model\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy72RPgly55q"
      },
      "source": [
        "**To pass this assignment, your model should achieve a training accuracy of at least 80%**. If your model didn't achieve this threshold, try training again with a different model architecture, consider increasing the number of unit in your `LSTM` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "1ab1f651-f23c-47d3-c8bb-5f1d94c662f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Take a look at the training curves of your model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjvED5A3qrn2"
      },
      "source": [
        "Before closing the assignment, be sure to also download the `history.pkl` file which contains the information of the training history of your model and will be used to compute your grade. You can download this file by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QRG73l6qE-c",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "98653b6d-bd8b-483c-b81c-4b5ec3310965"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_814f604a-699f-4ac9-b4af-ca136b14ec99\", \"history.pkl\", 3642)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdsMszk9zBs_"
      },
      "source": [
        "## See your model in action\n",
        "\n",
        "After all your work it is finally time to see your model generating text.\n",
        "\n",
        "Run the cell below to generate the next 100 words of a seed text.\n",
        "\n",
        "After submitting your assignment you are encouraged to try out training for different amounts of epochs and seeing how this affects the coherency of the generated text. Also try changing the seed text to see what you get!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee985d00-1e60-40f0-a8bb-60dfc587f693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope the false better tomb eyes ' heart enough summer's truth ' one ' so hide me that 'will ' ' ' 'will ' me thee ' ' ' tomb me ' yellow'd me taught thee ' ' ' thee last me ' art now is thee me found thee thee heart thee enlarged done thee have i all alone beweep my outcast state ' ' in thee is ' burn'd me all men thee stick'st smells to ' me thee me ' ' add me ' heart thee art one 'will ' me ' time ' time thou art more\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # Convert the text into sequences\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    # Pad the sequences\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    # Get the probabilities of predicting a word\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    # Choose the next word based on the maximum probability\n",
        "    predicted = np.argmax(predicted, axis=-1).item()\n",
        "    # Get the actual word from the word index\n",
        "    output_word = tokenizer.index_word[predicted]\n",
        "    # Append to the current text\n",
        "    seed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQVDbdcYqSux"
      },
      "source": [
        "## Download your notebook for grading\n",
        "\n",
        "Along with the `history.pkl` file earlier, you will also need to submit your solution notebook for grading. The following code cells will check if this notebook's grader metadata (i.e. hidden data in the notebook needed for grading) is not modified by your workspace. This will ensure that the autograder can evaluate your code properly. Depending on its output, you will either:\n",
        "\n",
        "* *if the metadata is intact*: Download the current notebook. Click on the File tab on the upper left corner of the screen then click on `Download -> Download .ipynb.` You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file.\n",
        "<br>\n",
        "\n",
        "* *if the metadata is missing*: A new notebook with your solutions will be created on this Colab workspace. It should be downloaded automatically and you can submit that to the grader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUEiIXZEShHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc99632-dde6-4378-d71b-93e742568a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-10 02:52:03--  https://storage.googleapis.com/tensorflow-1-public/colab_metadata_checker.py\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 173.194.218.128, 108.177.11.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1997 (2.0K) [text/x-python-script]\n",
            "Saving to: ‘colab_metadata_checker.py’\n",
            "\n",
            "\r          colab_met   0%[                    ]       0  --.-KB/s               \rcolab_metadata_chec 100%[===================>]   1.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-10 02:52:03 (35.1 MB/s) - ‘colab_metadata_checker.py’ saved [1997/1997]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download metadata checker\n",
        "!wget -nc https://storage.googleapis.com/tensorflow-1-public/colab_metadata_checker.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek87UXX7Sj6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21825b50-84b7-416e-ea98-47c11ef704cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grader metadata detected! You can download this notebook by clicking `File > Download > Download as .ipynb` and submit it to the grader!\n"
          ]
        }
      ],
      "source": [
        "import colab_metadata_checker\n",
        "\n",
        "# Please see the output of this cell to see which file you need to submit to the grader\n",
        "colab_metadata_checker.run('C3W4_Assignment_fixed.ipynb')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKS9ub6xYUpg"
      },
      "source": [
        "**Please disregard the following note if the notebook metadata is detected**\n",
        "\n",
        "_Note: Just in case the automatic download fails when the metadata is missing, you can also do these steps:_\n",
        "* _Click the Folder icon on the left side of this screen to open the File Manager._\n",
        "* _Click the Folder Refresh icon in the File Manager to see the latest files in the workspace. You should see a file ending with a `_fixed.ipynb`._\n",
        "* _Right-click on that file to save locally and submit it to the grader._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r-X-HXtSc8N"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a neural network capable of predicting the next word in a sequence of text!\n",
        "\n",
        "**We hope to see you in the next course of the specialization! Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "dlai_version": "1.2.0",
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}